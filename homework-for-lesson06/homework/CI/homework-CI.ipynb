{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Inference and Confidence Interval\n",
    "\n",
    "Suppose Google sampled 200 of its employees and measured how long they are gone for lunch. Load the data data/lunch_hour.txt into a Numpy array and compute the mean lunch hour of the sample\n",
    "\n",
    "What is the sampling distribution of the sample mean? Explain your answer.\n",
    "\n",
    "Compute the standard error  given the sample. Based on the the standard error and the sample mean, compute the 95% confidence interval  .\n",
    "\n",
    "Interpret what the 95% confidence interval implies about the lunch hours of Google employees in general\n",
    "\n",
    "If the sample size were smaller, how would that affect the 95% CI? Explain your answer. Suppose the sample size were 10, does your assumption from 2. still hold? Explain your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lunch = np.loadtxt('data/lunch_hour.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3,  2.5,  1.9,  2. ,  1.2,  1.7,  3. ,  1.4,  2. ,  2.4,  1.8,\n",
       "        3. ,  3. ,  3.2,  1.8,  2.9,  1.3,  2.5,  1.5,  1.8,  1.6,  1.6,\n",
       "        2.8,  2. ,  2. ,  2.7,  1.3,  3.1,  3.1,  1.4,  1.9,  1.6,  3.1,\n",
       "        2.6,  3.2,  2.1,  1.7,  2.6,  2.6,  1.7,  1.3,  1.5,  1.2,  2.9,\n",
       "        2. ,  1.2,  1.9,  2.7,  1.6,  1.5,  2.2,  2.1,  2.8,  2.9,  2.5,\n",
       "        1.4,  1.7,  2.9,  1.6,  2.2,  2.4,  2.8,  1.3,  2.4,  1.7,  2. ,\n",
       "        2.3,  1.8,  1.2,  1.5,  1.6,  1.2,  2.2,  1.3,  2.4,  2.4,  2.8,\n",
       "        2.6,  2.1,  2.8,  2.8,  1.6,  1.9,  3.2,  2.2,  1.5,  2.9,  1.8,\n",
       "        1.9,  2. ,  3.2,  2.7,  2.8,  1.4,  3.2,  3.1,  2.3,  1.6,  1.8,\n",
       "        1.7,  2. ,  1.3,  2.1,  2.5,  2.6,  2.5,  3. ,  2.8,  2.6,  2.6,\n",
       "        1.7,  2.8,  2.5,  2.3,  2.2,  2.2,  2. ,  1.5,  2.3,  2.2,  2.9,\n",
       "        1.8,  3.1,  2.2,  2.8,  2.1,  3. ,  2.4,  1.4,  2.7,  2.9,  2.5,\n",
       "        3.1,  2.5,  2.4,  2.5,  1.9,  2.1,  2.8,  3.1,  2.2,  1.5,  2.3,\n",
       "        2.4,  3.2,  1.2,  1.5,  3. ,  1.8,  1.6,  1.7,  2. ,  2.9,  2.4,\n",
       "        1.8,  1.3,  2.2,  1.6,  2.1,  1.6,  1.4,  1.6,  1.2,  2.6,  3.1,\n",
       "        2.9,  1.8,  1.7,  1.5,  2.4,  1.5,  2. ,  2.5,  2.5,  3. ,  2.9,\n",
       "        1.8,  3.1,  2.5,  2.7,  2.7,  2.1,  2.3,  3. ,  3. ,  2.2,  1.7,\n",
       "        1.4,  2. ,  2.1,  1.8,  1.4,  1.8,  2.1,  1.6,  3.1,  1.9,  1.8,\n",
       "        1.7,  1.9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57732984506259499"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(lunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1844999999999999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0460306338383265, 3.322969366161673)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.t.interval(0.95, len(lunch) - 1, np.mean(lunch), np.std(lunch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Assumed normality on distributuon because of size.\n",
    "# Smaller sample, larger difference for confidence interval (next code)\n",
    "# For smaller sampe we would need to use a different distribution which from\n",
    "# the class I suppose happens inside the statistics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0167401693186704, 3.3522598306813292)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.t.interval(0.95, len(lunch)/5 - 1, np.mean(lunch), np.std(lunch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
